{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def calcShannonEnt(dataSet):\n",
    "        numEntries = len(dataSet)\n",
    "        labelCounts = {}\n",
    "        for featVec in dataSet:\n",
    "            currentLabel = featVec[-1]\n",
    "            labelCounts[currentLabel] = labelCounts.get(currentLabel, 0) + 1\n",
    "        \n",
    "        shannonEnt = 0.0\n",
    "        for key in labelCounts:\n",
    "            prob = float(labelCounts[key]) / numEntries\n",
    "            shannonEnt -= prob * log(prob, 2)\n",
    "        return shannonEnt\n",
    "    \n",
    "    def splitDataSet(dataSet, index, value):\n",
    "        \"\"\"\n",
    "        index为选定的feature号\n",
    "        value为在该feature下给定的值\n",
    "        本function的作用为：\n",
    "        根据选定feature的值对dataset进行分组，feature value值相同的为同一组。\n",
    "        并且分组后的subDataSet中不包含选定的feature。\n",
    "        用于计算根据某feature分组后的信息熵。\n",
    "        \"\"\"\n",
    "        retDataSet = []\n",
    "        for featVec in dataSet:\n",
    "            if featVec[index] == value:\n",
    "                reducedFeatVec = featVec[:index]\n",
    "                reducedFeatVec.extend(featVec[index:])\n",
    "                retDataSet.append(reducedFeatVec)\n",
    "        return retDataSet\n",
    "    \n",
    "    def chooseBestFeatureSplit(dataSet):\n",
    "        numFeatures = len(dataSet[0] - 1)\n",
    "        baseEntropy = self.calcShannonEnt(dataSet)\n",
    "        bestInfoGain, BestFeature = 0.0, -1\n",
    "        for i in range(numFeatures):\n",
    "            featList = [example[i] for example in dataSet] # the all the value in one feature(column)\n",
    "            uniqueVals = set(featList) # get the unique values in this feature\n",
    "            newEntropy = 0.0\n",
    "            for value in uniqueVals:\n",
    "                subDataSet = splitDataSet(dataSet) # get the subDataSet with giving value\n",
    "                prob = len(subDataSet) / len(DataSet) # 这是在该feature下的值等于给定value值的概率\n",
    "                newEntropy += prob * self.calcShannonEnt(subDataSet) # calculate the subDataSet's ShannonEnt.\n",
    "            infoGain = baseEntropy - newEntropy\n",
    "            print (\"infoGain = \", infoGain, 'bestFeature=', i, baseEntropy, newEntropy)\n",
    "            if (infoGain > bestInfoGain):\n",
    "                bestInfoGain = infoGain\n",
    "                bestFeature = i\n",
    "        return bestFeature\n",
    "    \n",
    "    def majorityCnt(classList):\n",
    "        classCount = {}\n",
    "        for vote in classlist:\n",
    "            if vote not in classCount.keys():\n",
    "                classCount[vote] = 0\n",
    "            classCount[vote] += 1\n",
    "        sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True) # sort dict type\n",
    "        return sortedClassCount[0][0] # return the most common class in label column\n",
    "        \n",
    "    \n",
    "    def createTree(dataSet, columnNameList):\n",
    "        \"\"\"\n",
    "        The whole route map:\n",
    "        1. define the end conditions for recursion.\n",
    "        2. find the best feature from the original dataset\n",
    "        3. generate the unique value list of best feature.\n",
    "        4. split the original dataset into several subdataset according to \n",
    "        the different values in the best feature.\n",
    "        5. for every subdataset, repeat the step 1 to step 4 untill the \n",
    "        subdataset reach the end conditions.\n",
    "        6. use a dictionary to store the tree structure.\n",
    "        \"\"\"    \n",
    "        \n",
    "        \n",
    "        \"\"\"End condition 1: all labels have the same value (only 1 class)\"\"\"\n",
    "        classList = [example[-1] for example in dataSet]\n",
    "        # list.count(value): count the frequence of value occurred in this list\n",
    "        if classList.count(classList[1]) == len(classList):\n",
    "            return classList[0]\n",
    "        \n",
    "        \"\"\"\n",
    "        End condition 2: after using all features to split the dataset, the rest\n",
    "        dataset's labels still contain multiple classes.\n",
    "        \"\"\"\n",
    "        if len(dataSet[0] == 1): # the rest only contains the single column (label)\n",
    "            return majorityCnt(classList)\n",
    "        \n",
    "        bestFeat = self.chooseBestFeatureSplit(dataSet) # get the index of best feature\n",
    "        bestFeatName = columnNameList(bestFeat)\n",
    "        \n",
    "        myTree = {bestFeatName:{}}\n",
    "        del(columnNameList[bestFeat]) # delete the best feature name in the column name list\n",
    "        \n",
    "        featVals = [example[bestFeat] for example in dataSet]\n",
    "        UniqueVals = set(featVals)\n",
    "        \n",
    "        for value in UniqueVals:\n",
    "            subColumnNameList = ColumnNamList[:] # why we need this line?\n",
    "            \"\"\"\n",
    "            use recursion to generate branches for each subdataset.\n",
    "            Usually, createTree will return a dict-type object unless the subdataset reach the end condition.\n",
    "            \"\"\"\n",
    "            \n",
    "            # input: dict1 = {\"layer 1\": {\"layer 2\": 2}}\n",
    "            #        print (dict1[\"layer 1\"][\"layer 2\"])\n",
    "            # output: 2\n",
    "            myTree[bestFeatureName][value] = self.createTree(splitDataSet(dataSet, bestFeat, value), subColumnNameList)\n",
    "        \n",
    "        return myTree\n",
    "    \n",
    "    def classify(inputTree, featLabels, testVec):\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
