{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def calcShannonEnt(dataSet):\n",
    "        numEntries = len(dataSet)\n",
    "        labelCounts = {}\n",
    "        for featVec in dataSet:\n",
    "            currentLabel = featVec[-1]\n",
    "            labelCounts[currentLabel] = labelCounts.get(currentLabel, 0) + 1\n",
    "        \n",
    "        shannonEnt = 0.0\n",
    "        for key in labelCounts:\n",
    "            prob = float(labelCounts[key]) / numEntries\n",
    "            shannonEnt -= prob * log(prob, 2)\n",
    "        return shannonEnt\n",
    "    \n",
    "    def splitDataSet(dataSet, index, value):\n",
    "        \"\"\"\n",
    "        index为选定的feature号\n",
    "        value为在该feature下给定的值\n",
    "        本function的作用为：\n",
    "        根据选定feature的值对dataset进行分组，feature value值相同的为同一组。\n",
    "        并且分组后的subDataSet中不包含选定的feature。\n",
    "        用于计算根据某feature分组后的信息熵。\n",
    "        \"\"\"\n",
    "        retDataSet = []\n",
    "        for featVec in dataSet:\n",
    "            if featVec[index] == value:\n",
    "                reducedFeatVec = featVec[:index]\n",
    "                reducedFeatVec.extend(featVec[index:])\n",
    "                retDataSet.append(reducedFeatVec)\n",
    "        return retDataSet\n",
    "    \n",
    "    def chooseBestFeatureSplit(dataSet):\n",
    "        numFeatures = len(dataSet[0] - 1)\n",
    "        baseEntropy = self.calcShannonEnt(dataSet)\n",
    "        bestInfoGain, BestFeature = 0.0, -1\n",
    "        for i in range(numFeatures):\n",
    "            featList = [example[i] for example in dataSet] # the all the value in one feature(column)\n",
    "            uniqueVals = set(featList) # get the unique values in this feature\n",
    "            newEntropy = 0.0\n",
    "            for value in uniqueVals:\n",
    "                subDataSet = splitDataSet(dataSet) # get the subDataSet with giving value\n",
    "                prob = len(subDataSet) / len(DataSet) # 这是在该feature下的值等于给定value值的概率\n",
    "                newEntropy += prob * self.calcShannonEnt(subDataSet) # calculate the subDataSet's ShannonEnt.\n",
    "            infoGain = baseEntropy - newEntropy\n",
    "            print (\"infoGain = \", infoGain, 'bestFeature=', i, baseEntropy, newEntropy)\n",
    "            if (infoGain > bestInfoGain):\n",
    "                bestInfoGain = infoGain\n",
    "                bestFeature = i\n",
    "        return bestFeature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
