{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#0099ff size=4 face=\"黑体\">\n",
    "Classification And Regression Trees implement<br>\n",
    "@Author: Ge Chen<br>\n",
    "@Time: 2019-8-24<br>\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.1、附加 各常见树构造算法的划分分支方式\n",
    "还有一点要说明，构建决策树算法，常用到的是三个方法: ID3, C4.5, CART.\n",
    "三种方法区别是划分树的分支的方式:\n",
    "\n",
    "ID3 是信息增益分支\n",
    "C4.5 是信息增益率分支\n",
    "CART 做分类工作时，采用 GINI 值作为节点分裂的依据；回归时，采用样本的最小方差作为节点的分裂依据。\n",
    "工程上总的来说:\n",
    "\n",
    "CART 和 C4.5 之间主要差异在于分类结果上，CART 可以回归分析也可以分类，C4.5 只能做分类；C4.5 子节点是可以多分的，而 CART 是无数个二叉子节点；\n",
    "\n",
    "以此拓展出以 CART 为基础的 “树群” Random forest ， 以 回归树 为基础的 “树群” GBDT 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class regTree():\n",
    "    def loadDataSet(self, filename):\n",
    "        dataMat = []\n",
    "        with open(filename) as fr:\n",
    "            for line in fr.readlines():\n",
    "                curLine = line.strip().split('\\t')\n",
    "                fltLine = [float(x) for x in curLine]\n",
    "                dataMat.append(fltLine)\n",
    "        return dataMat\n",
    "    \n",
    "    def leafType(self, dataSet):\n",
    "        # use center of leaf dataset \n",
    "        return np.mean(dataSet[:, -1])\n",
    "    \n",
    "    def regErr(self, dataSet):\n",
    "        # use variance to stand for the error\n",
    "        return np.var(dataSet[:, -1]) * np.shape(dataSet)[0]\n",
    "    \n",
    "\n",
    "    def binSplitDataSet(self, dataSet, feature, value):\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            split dataSet according to the giving feature value\n",
    "            It uses dichotomy to split dataset.\n",
    "        Args:\n",
    "            dataSet -- dataset\n",
    "            feature -- giving feature index\n",
    "            value -- giving feature value\n",
    "        Returns:\n",
    "            mat0 -- subdataset with the feature value <= giving value\n",
    "            mat1 -- subdataset with the feature value > giving value\n",
    "        \"\"\"\n",
    "\n",
    "        # np.nonzzero(): return the subscripts with \"ture\"\n",
    "        # >>> test1 = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "        #     testRes = np.nonzero(test1 < 5)\n",
    "        # >>> testRes: (array([0, 1, 2, 3], dtype=int64),)\n",
    "        # >>> testRes: array([0, 1, 2, 3], dtype=int64)\n",
    "        mat0 = dataSet[np.nonzero(dataSet[:, feature] <= value)[0], :]\n",
    "        mat1 = dataSet[np.nonzero(dataSet[:, feature] > value)[0], :]\n",
    "        return mat0, mat1\n",
    "    \n",
    "    def chooseBestSplit(self, dataSet, ops = (1, 4)):\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            find the best splitting way and generate the leaf node\n",
    "            The best feature refers to the feature which can maximum \n",
    "            the error reduction after splitting.\n",
    "        Args:\n",
    "            dataSet -- data set\n",
    "            leafType -- the function used to generate leaf node\n",
    "            errType -- the function used to calculate error (total variance)\n",
    "            ops -- (minimum error reduction, minimum set size)\n",
    "        Returns:\n",
    "            bestIndex -- best feature's index\n",
    "            bestValue -- best feature value for splitting\n",
    "        \"\"\"\n",
    "        # 最小误差下降值, minimum error reduction.\n",
    "        # If the error reduction after splitting is smaller than this value, \n",
    "        # then the splitting will stop \n",
    "        tolS = ops[0]\n",
    "        \n",
    "        # minimum set size,\n",
    "        # If the set size is smaller than this value, stop splitting.\n",
    "        tolN = ops[1]\n",
    "        \n",
    "        # if all the labels in this dataset is same, stop splitting\n",
    "        if len(set(dataSet[:, -1].T.tolist()[0])) == 1: \n",
    "            return None, self.leafType(dataSet)        \n",
    "        m, n = np.shape(dataSet)\n",
    "        \n",
    "        # error before splitting\n",
    "        S = self.regErr(dataSet)\n",
    "        print (S)\n",
    "        # initialization\n",
    "        bestS, bestIndex, bestValue = np.inf, 0, 0\n",
    "        # start loop to find the best value\n",
    "        for featIndex in range(n - 1):\n",
    "            # dataSet[:, featIndex].T.tolist()[0] -- convert the giving feature into a list\n",
    "            for splitVal in set(dataSet[:, featIndex].T.tolist()[0]):\n",
    "                # split according different feature value\n",
    "                mat0, mat1 = self.binSplitDataSet(dataSet, featIndex, splitVal)\n",
    "                \n",
    "                # Ending condition I:the set number < minimum set size\n",
    "                # stop this loop step and start the next loop step\n",
    "                if (np.shape(mat0)[0] < tolN) or (np.shape(mat1)[0] < tolN):\n",
    "                    continue\n",
    "                newS = self.regErr(mat0) + self.regErr(mat1)\n",
    "                if newS < bestS:\n",
    "                    bestIndex = featIndex\n",
    "                    bestValue = splitVal\n",
    "                    bestS = newS\n",
    "        # complete the loop, judge if the splitting reach the ending conditions\n",
    "        # Ending condition II: the error reduction < minimum error reduction\n",
    "        if (S - bestS) < tolS:\n",
    "            return None, self.leafType(dataSet)\n",
    "        \n",
    "        # split dataset with best feature index and value\n",
    "        mat0, mat1 = self.binSplitDataSet(dataSet, bestIndex, bestValue)\n",
    "        \n",
    "        # Ending condition I: dataset size after splitting < minimum set size\n",
    "        if (np.shape(mat0)[0] < tolN) or (np.shape(mat1)[0] < tolN):\n",
    "            return None, self.leafType(dataSet)\n",
    "        \n",
    "        # return the best feature index and best feature value for the next splitting\n",
    "        return bestIndex, bestValue\n",
    "    \n",
    "    def createTree(self, dataSet, ops=(1,4)):\n",
    "        \"\"\"\n",
    "        Desc:\n",
    "            create tree with recursion.\n",
    "        Args:\n",
    "            dataSet -- data set\n",
    "            leafType -- the function used to generate leaf node\n",
    "            errType -- the function used to calculate error (total variance)\n",
    "            ops -- (minimum error reduction, minimum set size)\n",
    "        Returns:\n",
    "            retTree -- the decision tree\n",
    "        \"\"\"\n",
    "        \n",
    "        # choose the best way to split the dataset, get the best feature and best feature value\n",
    "        feat, val = self.chooseBestSplit(dataSet, ops)\n",
    "        \n",
    "        # if the splitting reaches a ending condition, stop splitting, return the value\n",
    "        if feat is None:\n",
    "            return val\n",
    "        \n",
    "        # if the splitting does not reach the ending conditions, \n",
    "        # store the best value and feature\n",
    "        retTree = {}\n",
    "        retTree['spInd'] = feat\n",
    "        retTree['spVal'] = val\n",
    "        \n",
    "        # split the data set with the best value and feature and \n",
    "        lSet, rSet = self.binSplitDataSet(dataSet, feat, val)\n",
    "        # use recursion to generate the left child node and right child node\n",
    "        retTree['left'] = self.createTree(lSet, ops)\n",
    "        retTree['right'] = self.createTree(rSet, ops)\n",
    "        \n",
    "        return retTree\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.380639385992986\n",
      "3.382419701775143\n",
      "4.972326818084716\n"
     ]
    }
   ],
   "source": [
    "    # 回归树\n",
    "    RT = regTree()\n",
    "    myDat = RT.loadDataSet(r'data\\Ch09\\data1.txt')\n",
    "    # myDat = loadDataSet('data/9.RegTrees/data2.txt')\n",
    "    # print 'myDat=', myDat\n",
    "    myMat = np.mat(myDat)\n",
    "    # print 'myMat=',  myMat\n",
    "\n",
    "    myTree = RT.createTree(myMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spInd': 0,\n",
       " 'spVal': 0.48813,\n",
       " 'left': -0.04465028571428572,\n",
       " 'right': 1.0180967672413792}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
